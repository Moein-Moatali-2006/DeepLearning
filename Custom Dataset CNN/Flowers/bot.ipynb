{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hGSorMMS0bH"
      },
      "outputs": [],
      "source": [
        "import telebot\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNz5n-bBS47v"
      },
      "outputs": [],
      "source": [
        "bot = telebot.TeleBot(\"7687972629:AAFR7GbE044QQls156eZv6L5CUaibXeR1Cw\", parse_mode=\"HTML\")\n",
        "model = load_model('/content/drive/MyDrive/model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAQqtdOZNkoQ",
        "outputId": "d9043c19-0d42-4512-923b-cdd174826ceb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
          ]
        }
      ],
      "source": [
        "flower_dict = {\n",
        "    0: \"Bluebell\",\n",
        "    1: \"Buttercup\",\n",
        "    2: \"Coltsfoot\",\n",
        "    3: \"Cowslip\",\n",
        "    4: \"Crocus\",\n",
        "    5: \"Daffodil\",\n",
        "    6: \"Daisy\",\n",
        "    7: \"Dandelion\",\n",
        "    8: \"Fritillary\",\n",
        "    9: \"Iris\",\n",
        "    10: \"Lily Valley\",\n",
        "    11: \"Pansy\",\n",
        "    12: \"Snowdrop\",\n",
        "    13: \"Sunflower\",\n",
        "    14: \"Tigerlily\",\n",
        "    15: \"Tulip\",\n",
        "    16: \"Windflower\"\n",
        "}\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "@bot.message_handler(commands=['start'])\n",
        "def send_welcome(message):\n",
        "    bot.reply_to(message, f\"Hi {message.from_user.first_name}! ğŸŒ¸ Send me a flower picture to identify it.\")\n",
        "\n",
        "@bot.message_handler(content_types=['photo'])\n",
        "def handle_photo(message):\n",
        "    file_id = message.photo[-1].file_id\n",
        "    file_info = bot.get_file(file_id)\n",
        "    downloaded_file = bot.download_file(file_info.file_path)\n",
        "\n",
        "    with open(\"image.jpg\", \"wb\") as file:\n",
        "        file.write(downloaded_file)\n",
        "\n",
        "    bot.reply_to(message, \"ğŸ”„ Processing the image...\")\n",
        "\n",
        "    image = load_img(\"image.jpg\", target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    image_gen = datagen.flow(image, batch_size=1)\n",
        "    image_processed = next(image_gen)\n",
        "\n",
        "    output = model.predict(image_processed)\n",
        "    predict = np.argmax(output)\n",
        "    flower_name = flower_dict.get(predict, \"Unknown Flower\")\n",
        "\n",
        "    bot.reply_to(message,f\"ğŸŒº This looks like a <b>{flower_name}</b>!\")\n",
        "\n",
        "bot.polling()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
