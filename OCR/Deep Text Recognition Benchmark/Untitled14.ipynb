{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_X-t1_GbUM8V"
      },
      "outputs": [],
      "source": [
        "! pip install -q lmdb pillow torchvision nltk natsort"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/clovaai/deep-text-recognition-benchmark.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9jVVKPyf_Q8",
        "outputId": "beb07e8d-f3b5-4d7c-a32f-fbcf730cd739"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-text-recognition-benchmark'...\n",
            "remote: Enumerating objects: 499, done.\u001b[K\n",
            "remote: Counting objects: 100% (225/225), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 499 (delta 208), reused 200 (delta 200), pack-reused 274 (from 1)\u001b[K\n",
            "Receiving objects: 100% (499/499), 3.05 MiB | 38.14 MiB/s, done.\n",
            "Resolving deltas: 100% (308/308), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd deep-text-recognition-benchmark/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQzX3ORwhFJv",
        "outputId": "83edd4ab-a5c0-4935-e289-2d46d53037f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-text-recognition-benchmark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown 1ubkg7E2vGEOqS4K_quwf9Vl-i8IVpklM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwGXmqJZhM-3",
        "outputId": "eae4e9aa-d2ec-4c30-b0c5-6fa6a2bfa26c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ubkg7E2vGEOqS4K_quwf9Vl-i8IVpklM\n",
            "From (redirected): https://drive.google.com/uc?id=1ubkg7E2vGEOqS4K_quwf9Vl-i8IVpklM&confirm=t&uuid=0cae3436-337a-4ce5-932d-cff3c29a9845\n",
            "To: /content/deep-text-recognition-benchmark/plate_img-train.zip\n",
            "100% 196M/196M [00:04<00:00, 41.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown 1AL5Zsg2hDqcwF8ZmR0MJTbjgXIoE5W-I"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13qdeEMEiXKE",
        "outputId": "5643e09f-a53c-4596-b849-db7ac587d447"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1AL5Zsg2hDqcwF8ZmR0MJTbjgXIoE5W-I\n",
            "From (redirected): https://drive.google.com/uc?id=1AL5Zsg2hDqcwF8ZmR0MJTbjgXIoE5W-I&confirm=t&uuid=1a1acf26-98de-4f5f-b938-2c0e4aef5a93\n",
            "To: /content/deep-text-recognition-benchmark/plate_img-validation.zip\n",
            "100% 27.2M/27.2M [00:01<00:00, 22.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/deep-text-recognition-benchmark/plate_img-train.zip -d /content/Dataset/train/\n",
        "!unzip /content/deep-text-recognition-benchmark/plate_img-validation.zip -d /content/Dataset/validation/"
      ],
      "metadata": {
        "id": "pOtzzA7Missj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "train_dir = '/content/Dataset/train/train'\n",
        "output_file = '/content/Data/gt.txt'\n",
        "lines = []\n",
        "\n",
        "for filename in os.listdir(train_dir):\n",
        "    if filename.endswith('.xml'):\n",
        "        xml_path = os.path.join(train_dir, filename)\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        image_name = root.find('filename').text\n",
        "        image_path = os.path.join(train_dir, image_name)\n",
        "\n",
        "        chars = []\n",
        "        for obj in root.findall('object'):\n",
        "            name = obj.find('name').text\n",
        "            bbox = obj.find('bndbox')\n",
        "            xmin = int(bbox.find('xmin').text)\n",
        "            chars.append((xmin, name))\n",
        "\n",
        "        # Sort characters from left to right\n",
        "        chars = sorted(chars, key=lambda x: x[0])\n",
        "        label = ''.join([char[1] for char in chars])\n",
        "\n",
        "        lines.append(f'{image_path}\\t{label}')\n",
        "\n",
        "# Save to gt.txt\n",
        "with open(os.path.join(train_dir, output_file), 'w', encoding='utf-8') as f:\n",
        "    for line in lines:\n",
        "        f.write(line + '\\n')\n",
        "\n",
        "print(f'Done! {len(lines)} items written to {output_file}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWDkI56djWb0",
        "outputId": "aa8cb1bd-e05d-42dd-e4bb-8d615dccba26"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done! 19381 items written to /content/Data/gt.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "train_dir = '/content/Dataset/validation/validation'\n",
        "output_file = '/content/Data/gt_validation.txt'\n",
        "lines = []\n",
        "\n",
        "for filename in os.listdir(train_dir):\n",
        "    if filename.endswith('.xml'):\n",
        "        xml_path = os.path.join(train_dir, filename)\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        image_name = root.find('filename').text\n",
        "        image_path = os.path.join(train_dir, image_name)\n",
        "\n",
        "        chars = []\n",
        "        for obj in root.findall('object'):\n",
        "            name = obj.find('name').text\n",
        "            bbox = obj.find('bndbox')\n",
        "            xmin = int(bbox.find('xmin').text)\n",
        "            chars.append((xmin, name))\n",
        "\n",
        "        # Sort characters from left to right\n",
        "        chars = sorted(chars, key=lambda x: x[0])\n",
        "        label = ''.join([char[1] for char in chars])\n",
        "\n",
        "        lines.append(f'{image_path}\\t{label}')\n",
        "\n",
        "# Save to gt.txt\n",
        "with open(os.path.join(train_dir, output_file), 'w', encoding='utf-8') as f:\n",
        "    for line in lines:\n",
        "        f.write(line + '\\n')\n",
        "\n",
        "print(f'Done! {len(lines)} items written to {output_file}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BICKdc20kHOH",
        "outputId": "87baafef-b0bc-4c5e-a52c-d7b75710f016"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done! 2805 items written to /content/Data/gt_validation.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "source_dir = '/content/Dataset/train/train'\n",
        "destination_dir = '/content/Data/train'\n",
        "\n",
        "os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(source_dir):\n",
        "    if filename.lower().endswith('.jpg'):\n",
        "        src_path = os.path.join(source_dir, filename)\n",
        "        dst_path = os.path.join(destination_dir, filename)\n",
        "        shutil.move(src_path, dst_path)\n",
        "\n",
        "print(\"Done train data!\")\n",
        "\n",
        "source_dir = '/content/Dataset/validation/validation'\n",
        "destination_dir = '/content/Data/validation'\n",
        "\n",
        "os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(source_dir):\n",
        "    if filename.lower().endswith('.jpg'):\n",
        "        src_path = os.path.join(source_dir, filename)\n",
        "        dst_path = os.path.join(destination_dir, filename)\n",
        "        shutil.move(src_path, dst_path)\n",
        "\n",
        "print(\"Done validation data !\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uabYwU4kTpA",
        "outputId": "fdfc3ab9-4477-4562-9e1c-e37d49ebd9c4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done train data!\n",
            "Done validation data !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py \\\n",
        "--train_data data_lmdb_release/training --valid_data data_lmdb_release/validation \\\n",
        "--select_data / --batch_ratio 1 \\\n",
        "--Transformation None --FeatureExtraction VGG --SequenceModeling BiLSTM --Prediction CTC\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DveMDosmSaW",
        "outputId": "2b218526-6a24-412f-cd0e-3a82374d02aa"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering the images containing characters which are not in opt.character\n",
            "Filtering the images whose label is longer than opt.batch_max_length\n",
            "dataset_root:    data_lmdb_release/validation\t dataset: /\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/deep-text-recognition-benchmark/train.py\", line 317, in <module>\n",
            "    train(opt)\n",
            "  File \"/content/deep-text-recognition-benchmark/train.py\", line 35, in train\n",
            "    valid_dataset, valid_dataset_log = hierarchical_dataset(root=opt.valid_data, opt=opt)\n",
            "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/deep-text-recognition-benchmark/dataset.py\", line 130, in hierarchical_dataset\n",
            "    concatenated_dataset = ConcatDataset(dataset_list)\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\", line 328, in __init__\n",
            "    assert len(self.datasets) > 0, \"datasets should not be an empty iterable\"  # type: ignore[arg-type]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: datasets should not be an empty iterable\n"
          ]
        }
      ]
    }
  ]
}