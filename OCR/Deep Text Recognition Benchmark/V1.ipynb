{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxVfbBDDCB_G"
      },
      "source": [
        "## 1- Installing prerequisites and cloning the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7InVm_GCQJ2"
      },
      "outputs": [],
      "source": [
        "!pip install -q lmdb fire gdown\n",
        "!git clone https://github.com/clovaai/deep-text-recognition-benchmark.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yeh9EzZCiYV"
      },
      "source": [
        "## 2- Downloading pretrained weights and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qdk8zp3GCkcF"
      },
      "outputs": [],
      "source": [
        "!gdown 1ubkg7E2vGEOqS4K_quwf9Vl-i8IVpklM  #  فایل zip train\n",
        "!gdown 1AL5Zsg2hDqcwF8ZmR0MJTbjgXIoE5W-I  #  فایل zip validation\n",
        "\n",
        "# باز کردن zip ها\n",
        "!unzip -q /content/plate_img-train.zip -d /content/Dataset/\n",
        "!unzip -q /content/plate_img-validation.zip -d /content/Dataset/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwNvZLN8Cuov"
      },
      "source": [
        "## 3- Preparing GT (Ground Truth) files for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnm25HgGC2-3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "train_dir = '/content/Dataset/train'\n",
        "output_file = '/content/deep-text-recognition-benchmark/data/gt_train.txt'\n",
        "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
        "lines = []\n",
        "\n",
        "for filename in os.listdir(train_dir):\n",
        "    if filename.endswith('.xml'):\n",
        "        xml_path = os.path.join(train_dir, filename)\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        image_name = root.find('filename').text\n",
        "        image_path = os.path.join('/content/deep-text-recognition-benchmark/data/train', image_name)\n",
        "\n",
        "        chars = []\n",
        "        for obj in root.findall('object'):\n",
        "            name = obj.find('name').text\n",
        "            xmin = int(obj.find('bndbox').find('xmin').text)\n",
        "            chars.append((xmin, name))\n",
        "\n",
        "        chars.sort(key=lambda x: x[0])\n",
        "        label = ''.join([char[1] for char in chars])\n",
        "        lines.append(f'{image_path}\\t{label}')\n",
        "\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    f.write('\\n'.join(lines))\n",
        "\n",
        "print(f'Done! {len(lines)} items written to {output_file}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "سلول 4 – آماده‌سازی فایل‌های GT برای validation"
      ],
      "metadata": {
        "id": "ZxdeOu9flpau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dir = '/content/Dataset/validation'\n",
        "output_file = '/content/deep-text-recognition-benchmark/data/gt_validation.txt'\n",
        "lines = []\n",
        "\n",
        "for filename in os.listdir(valid_dir):\n",
        "    if filename.endswith('.xml'):\n",
        "        xml_path = os.path.join(valid_dir, filename)\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        image_name = root.find('filename').text\n",
        "        image_path = os.path.join('/content/deep-text-recognition-benchmark/data/validation', image_name)\n",
        "\n",
        "\n",
        "        chars = []\n",
        "        for obj in root.findall('object'):\n",
        "            name = obj.find('name').text\n",
        "            xmin = int(obj.find('bndbox').find('xmin').text)\n",
        "            chars.append((xmin, name))\n",
        "\n",
        "        chars.sort(key=lambda x: x[0])\n",
        "        label = ''.join([char[1] for char in chars])\n",
        "        lines.append(f'{image_path}\\t{label}')\n",
        "\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    f.write('\\n'.join(lines))\n",
        "\n",
        "print(f'Done! {len(lines)} items written to {output_file}')\n"
      ],
      "metadata": {
        "id": "fRnp_fXPltNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "سلول 5 – جابه‌جایی تصاویر به مسیر data/train و data/validation"
      ],
      "metadata": {
        "id": "KKGkXNY0l3it"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Move train images\n",
        "src = '/content/Dataset/train'\n",
        "dst = '/content/deep-text-recognition-benchmark/data/train'\n",
        "os.makedirs(dst, exist_ok=True)\n",
        "\n",
        "for file in os.listdir(src):\n",
        "    if file.endswith('.jpg'):\n",
        "        shutil.move(os.path.join(src, file), os.path.join(dst, file))\n",
        "\n",
        "# Move validation images\n",
        "src = '/content/Dataset/validation'\n",
        "dst = '/content/deep-text-recognition-benchmark/data/validation'\n",
        "os.makedirs(dst, exist_ok=True)\n",
        "\n",
        "for file in os.listdir(src):\n",
        "    if file.endswith('.jpg'):\n",
        "        shutil.move(os.path.join(src, file), os.path.join(dst, file))\n",
        "\n",
        "print(\"Train and validation images moved.\")\n"
      ],
      "metadata": {
        "id": "KbxDT2aCl7FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🟢 سلول 6 – ساخت LMDB دیتاست"
      ],
      "metadata": {
        "id": "5lGXz2xSl-ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deep-text-recognition-benchmark\n",
        "\n",
        "!python3 create_lmdb_dataset.py --inputPath data/train --gtFile data/gt_train.txt --outputPath dataset/train\n",
        "!python3 create_lmdb_dataset.py --inputPath data/validation --gtFile data/gt_validation.txt --outputPath dataset/validation"
      ],
      "metadata": {
        "id": "dOG_FOz3mA-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py \\\n",
        "--train_data dataset/train --valid_data dataset/validation \\\n",
        "--select_data / --batch_ratio 1 --batch_max_length 8 --valInterval 100 \\\n",
        "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn\n"
      ],
      "metadata": {
        "id": "21IRZbQbmKaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "/content/\n",
        "│\n",
        "├── Dataset/\n",
        "│   ├── train/\n",
        "│   │   ├── *.jpg\n",
        "│   │   └── *.xml\n",
        "│   └── validation/\n",
        "│       ├── *.jpg\n",
        "│       └── *.xml\n",
        "│\n",
        "└── deep-text-recognition-benchmark/\n",
        "    ├── data/\n",
        "    │   ├── gt_train.txt\n",
        "    │   ├── gt_validation.txt\n",
        "    │   ├── train/         ← عکس‌های train\n",
        "    │   └── validation/    ← عکس‌های validation\n",
        "    └── dataset/\n",
        "        ├── train/         ← LMDB ساخته شده\n",
        "        └── validation/    ← LMDB ساخته شده\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "FCBzGoRZmRcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _accumulate(iterable):\n",
        "    'Return running totals'\n",
        "    total = 0\n",
        "    for value in iterable:\n",
        "        total += value\n",
        "        yield total"
      ],
      "metadata": {
        "id": "NGNrSifOmSZ1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}