{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Persian License Plate Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Installing the required libraries on Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBHGzonFnMfl"
      },
      "outputs": [],
      "source": [
        "# Google Colab\n",
        "!pip install -q torchvision==0.15.1  numpy==1.23.5 lmdb fire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Downloading the repository used in the program\n",
        "Repository link address:\n",
        "[Deep Text Recognition Benchmark](https://github.com/clovaai/deep-text-recognition-benchmark)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-Eqg5mjacKr"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/clovaai/deep-text-recognition-benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNUzir2scrIf",
        "outputId": "5367147a-74ff-4d6d-a163-80b1b73720c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/deep-text-recognition-benchmark\n"
          ]
        }
      ],
      "source": [
        "%cd deep-text-recognition-benchmark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download pretrained model from :\n",
        "[models](https://drive.google.com/drive/folders/15WPsuPJDCzhp2SvYZLRj8mAlT3zmoAMW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qPQZKjKcx5E"
      },
      "outputs": [],
      "source": [
        "!gdown 1b59rXuGGmKne1AuHnkgDzoYgKeETNMv9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset link :\n",
        "[IR-LPR](https://github.com/mut-deep/IR-LPR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjnjvd5Rc2Fk",
        "outputId": "96ae2dce-9189-423a-b79f-98520d9037ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1PBbW1I7Itdf83bH_p60vo3_jrGTS0yLM\n",
            "From (redirected): https://drive.google.com/uc?id=1PBbW1I7Itdf83bH_p60vo3_jrGTS0yLM&confirm=t&uuid=b117a1f7-94ba-492d-8f56-025646fff676\n",
            "To: /content/deep-text-recognition-benchmark/plate_image_with_dummy-train.zip\n",
            "100% 710M/710M [00:20<00:00, 34.3MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1yZYdSNYBPXOoT_QySlH2RVTQS0AySA1z\n",
            "From (redirected): https://drive.google.com/uc?id=1yZYdSNYBPXOoT_QySlH2RVTQS0AySA1z&confirm=t&uuid=aed8048f-7596-434c-9c25-1e8a1697cdde\n",
            "To: /content/deep-text-recognition-benchmark/plate_image_with_dummy-validation.zip\n",
            "100% 78.4M/78.4M [00:01<00:00, 40.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1PBbW1I7Itdf83bH_p60vo3_jrGTS0yLM\n",
        "!gdown 1yZYdSNYBPXOoT_QySlH2RVTQS0AySA1z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb5f2tKcd8UQ"
      },
      "outputs": [],
      "source": [
        "!unzip /content/deep-text-recognition-benchmark/plate_image_with_dummy-train.zip -d /content/deep-text-recognition-benchmark/data\n",
        "!unzip /content/deep-text-recognition-benchmark/plate_image_with_dummy-validation.zip -d /content/deep-text-recognition-benchmark/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Processing and labeling the train and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wczynzI1lNmb",
        "outputId": "686963e0-f6dc-404f-ce14-115a54e686a4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from lxml import etree\n",
        "\n",
        "dict = {\n",
        "        'A': 'الف',\n",
        "        'B': 'ب',\n",
        "        'P': 'پ',\n",
        "        'T': 'ت',\n",
        "        'Y': 'ث',\n",
        "        'Z': 'ز',\n",
        "        'X': 'ش',\n",
        "        'E': 'ع',\n",
        "        'F': 'ف',\n",
        "        'K': 'ک',\n",
        "        'G': 'گ',\n",
        "        'D': 'D',\n",
        "        'S': 'S',\n",
        "        'J': 'ج',\n",
        "        'W': 'د',\n",
        "        'C': 'س',\n",
        "        'U': 'ص',\n",
        "        'R': 'ط',\n",
        "        'Q': 'ق',\n",
        "        'L': 'ل',\n",
        "        'M': 'م',\n",
        "        'N': 'ن',\n",
        "        'V': 'و',\n",
        "        'H': 'ه',\n",
        "        'I': 'ی',\n",
        "        '0': '۰',\n",
        "        '1': '۱',\n",
        "        '2': '۲',\n",
        "        '3': '۳',\n",
        "        '4': '۴',\n",
        "        '5': '۵',\n",
        "        '6': '۶',\n",
        "        '7': '۷',\n",
        "        '8': '۸',\n",
        "        '9': '۹',\n",
        "          '@': 'ویلچر',\n",
        "    }\n",
        "\n",
        "xml_dir = \"/content/deep-text-recognition-benchmark/dataset/train\"\n",
        "labels_txt_file = \"/content/deep-text-recognition-benchmark/dataset/gt_train.txt\"\n",
        "\n",
        "os.makedirs(os.path.dirname(labels_txt_file), exist_ok=True)\n",
        "\n",
        "def extract_names(xml_file, labels_txt_file):\n",
        "    parser = etree.XMLParser(encoding=\"utf-8\")\n",
        "    tree = etree.parse(xml_file, parser=parser)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    xml_file_name = os.path.splitext(os.path.basename(xml_file))[0]\n",
        "\n",
        "    with open(labels_txt_file, 'a', encoding='utf-8') as txt_file:\n",
        "        txt_file.write(f\"train/{xml_file_name}.jpg\\t\")\n",
        "        for name_element in root.iter('name'):\n",
        "            name = name_element.text.strip() if name_element.text else \"\"\n",
        "            txt_file.write(dict.get(name, \"@\"))\n",
        "        txt_file.write(\"\\n\")\n",
        "\n",
        "for xml_file in os.listdir(xml_dir):\n",
        "    if xml_file.endswith('.xml'):\n",
        "        xml_file_path = os.path.join(xml_dir, xml_file)\n",
        "        extract_names(xml_file_path, labels_txt_file)\n",
        "\n",
        "print(\"Labels saved gt_train.txt \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP3_da64liwO",
        "outputId": "92fb28ab-c041-4165-dc8d-88b7341b3de1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from lxml import etree\n",
        "\n",
        "dict = {\n",
        "        'A': 'الف',\n",
        "        'B': 'ب',\n",
        "        'P': 'پ',\n",
        "        'T': 'ت',\n",
        "        'Y': 'ث',\n",
        "        'Z': 'ز',\n",
        "        'X': 'ش',\n",
        "        'E': 'ع',\n",
        "        'F': 'ف',\n",
        "        'K': 'ک',\n",
        "        'G': 'گ',\n",
        "        'D': 'D',\n",
        "        'S': 'S',\n",
        "        'J': 'ج',\n",
        "        'W': 'د',\n",
        "        'C': 'س',\n",
        "        'U': 'ص',\n",
        "        'R': 'ط',\n",
        "        'Q': 'ق',\n",
        "        'L': 'ل',\n",
        "        'M': 'م',\n",
        "        'N': 'ن',\n",
        "        'V': 'و',\n",
        "        'H': 'ه',\n",
        "        'I': 'ی',\n",
        "        '0': '۰',\n",
        "        '1': '۱',\n",
        "        '2': '۲',\n",
        "        '3': '۳',\n",
        "        '4': '۴',\n",
        "        '5': '۵',\n",
        "        '6': '۶',\n",
        "        '7': '۷',\n",
        "        '8': '۸',\n",
        "        '9': '۹',\n",
        "          '@': 'ویلچر',\n",
        "    }\n",
        "\n",
        "xml_dir = \"/content/deep-text-recognition-benchmark/dataset/validation\"\n",
        "labels_txt_file = \"/content/deep-text-recognition-benchmark/dataset/gt_valid.txt\"\n",
        "\n",
        "os.makedirs(os.path.dirname(labels_txt_file), exist_ok=True)\n",
        "\n",
        "def extract_names(xml_file, labels_txt_file):\n",
        "    parser = etree.XMLParser(encoding=\"utf-8\")\n",
        "    tree = etree.parse(xml_file, parser=parser)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    xml_file_name = os.path.splitext(os.path.basename(xml_file))[0]\n",
        "\n",
        "    with open(labels_txt_file, 'a', encoding='utf-8') as txt_file:\n",
        "        txt_file.write(f\"validation/{xml_file_name}.jpg\\t\")\n",
        "        for name_element in root.iter('name'):\n",
        "            name = name_element.text.strip() if name_element.text else \"\"\n",
        "            txt_file.write(dict.get(name, \"@\"))\n",
        "        txt_file.write(\"\\n\")\n",
        "\n",
        "for xml_file in os.listdir(xml_dir):\n",
        "    if xml_file.endswith('.xml'):\n",
        "        xml_file_path = os.path.join(xml_dir, xml_file)\n",
        "        extract_names(xml_file_path, labels_txt_file)\n",
        "\n",
        "print(\"Labels saved gt_valid.txt \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a dataset likes lmdb for train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIKTTeXEp-ij"
      },
      "outputs": [],
      "source": [
        "!python3 create_lmdb_dataset.py \\\n",
        "--inputPath /content/deep-text-recognition-benchmark/dataset/ \\\n",
        "--gtFile /content/deep-text-recognition-benchmark/dataset/gt_train.txt \\\n",
        "--outputPath /content/deep-text-recognition-benchmark/LMDB_dataset/train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a dataset likes lmdb for validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWVtjNC0zz9E"
      },
      "outputs": [],
      "source": [
        "!python3 create_lmdb_dataset.py \\\n",
        "    --inputPath /content/deep-text-recognition-benchmark/dataset/ \\\n",
        "    --gtFile /content/deep-text-recognition-benchmark/dataset/gt_valid.txt \\\n",
        "    --outputPath /content/deep-text-recognition-benchmark/LMDB_dataset/validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQcaP3Qzmf9l",
        "outputId": "0907da8d-c00f-4cc1-cd42-50f1d610d59f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtering the images containing characters which are not in opt.character\n",
            "Filtering the images whose label is longer than opt.batch_max_length\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root: /content/deep-text-recognition-benchmark/DTRB_LMDB/train\n",
            "opt.select_data: ['/']\n",
            "opt.batch_ratio: ['1']\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    /content/deep-text-recognition-benchmark/DTRB_LMDB/train\t dataset: /\n",
            "sub-directory:\t/.\t num samples: 41222\n",
            "num total samples of /: 41222 x 1.0 (total_data_usage_ratio) = 41222\n",
            "num samples of / per batch: 192 x 1.0 (batch_ratio) = 192\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "--------------------------------------------------------------------------------\n",
            "Total_batch_size: 192 = 192\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    /content/deep-text-recognition-benchmark/DTRB_LMDB/validation\t dataset: /\n",
            "sub-directory:\t/.\t num samples: 4934\n",
            "--------------------------------------------------------------------------------\n",
            "model input parameters 32 100 20 1 512 256 38 8 TPS ResNet BiLSTM Attn\n",
            "Skip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\n",
            "Skip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\n",
            "Model:\n",
            "DataParallel(\n",
            "  (module): Model(\n",
            "    (Transformation): TPS_SpatialTransformerNetwork(\n",
            "      (LocalizationNetwork): LocalizationNetwork(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (6): ReLU(inplace=True)\n",
            "          (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (10): ReLU(inplace=True)\n",
            "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (14): ReLU(inplace=True)\n",
            "          (15): AdaptiveAvgPool2d(output_size=1)\n",
            "        )\n",
            "        (localization_fc1): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "        )\n",
            "        (localization_fc2): Linear(in_features=256, out_features=40, bias=True)\n",
            "      )\n",
            "      (GridGenerator): GridGenerator()\n",
            "    )\n",
            "    (FeatureExtraction): ResNet_FeatureExtractor(\n",
            "      (ConvNet): ResNet(\n",
            "        (conv0_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn0_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv0_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn0_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (layer1): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (layer2): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
            "        (layer3): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (4): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (layer4): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv4_1): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n",
            "        (bn4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv4_2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
            "        (bn4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
            "    (SequenceModeling): Sequential(\n",
            "      (0): BidirectionalLSTM(\n",
            "        (rnn): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "      (1): BidirectionalLSTM(\n",
            "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (Prediction): Attention(\n",
            "      (attention_cell): AttentionCell(\n",
            "        (i2h): Linear(in_features=256, out_features=256, bias=False)\n",
            "        (h2h): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (score): Linear(in_features=256, out_features=1, bias=False)\n",
            "        (rnn): LSTMCell(294, 256)\n",
            "      )\n",
            "      (generator): Linear(in_features=256, out_features=38, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Trainable params num :  49555182\n",
            "Optimizer:\n",
            "Adadelta (\n",
            "Parameter Group 0\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    lr: 1\n",
            "    maximize: False\n",
            "    rho: 0.95\n",
            "    weight_decay: 0\n",
            ")\n",
            "------------ Options -------------\n",
            "exp_name: TPS-ResNet-BiLSTM-Attn-Seed1111\n",
            "train_data: /content/deep-text-recognition-benchmark/DTRB_LMDB/train\n",
            "valid_data: /content/deep-text-recognition-benchmark/DTRB_LMDB/validation\n",
            "manualSeed: 1111\n",
            "workers: 4\n",
            "batch_size: 192\n",
            "num_iter: 4500\n",
            "valInterval: 500\n",
            "saved_model: \n",
            "FT: False\n",
            "adam: False\n",
            "lr: 1\n",
            "beta1: 0.9\n",
            "rho: 0.95\n",
            "eps: 1e-08\n",
            "grad_clip: 5\n",
            "baiduCTC: False\n",
            "select_data: ['/']\n",
            "batch_ratio: ['1']\n",
            "total_data_usage_ratio: 1.0\n",
            "batch_max_length: 8\n",
            "imgH: 32\n",
            "imgW: 100\n",
            "rgb: False\n",
            "character: 0123456789abcdefghijklmnopqrstuvwxyz\n",
            "sensitive: False\n",
            "PAD: False\n",
            "data_filtering_off: False\n",
            "Transformation: TPS\n",
            "FeatureExtraction: ResNet\n",
            "SequenceModeling: BiLSTM\n",
            "Prediction: Attn\n",
            "num_fiducial: 20\n",
            "input_channel: 1\n",
            "output_channel: 512\n",
            "hidden_size: 256\n",
            "num_gpu: 1\n",
            "num_class: 38\n",
            "---------------------------------------\n",
            "\n",
            "[1/4500] Train loss: 3.65781, Valid loss: 3.52808, Elapsed_time: 16.16292\n",
            "Current_accuracy : 0.000, Current_norm_ED  : 0.01\n",
            "Best_accuracy    : 0.000, Best_norm_ED     : 0.01\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "22u18768                  | kk                        | 0.0013\tFalse\n",
            "98w78299                  | kk                        | 0.0015\tFalse\n",
            "45r89344                  | qqqqqq                    | 0.0000\tFalse\n",
            "76k97799                  | 2222                      | 0.0000\tFalse\n",
            "62v75911                  | qqqqqqqq                  | 0.0000\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "[500/4500] Train loss: 2.13637, Valid loss: 1.62226, Elapsed_time: 445.86154\n",
            "Current_accuracy : 0.041, Current_norm_ED  : 0.38\n",
            "Best_accuracy    : 0.041, Best_norm_ED     : 0.38\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "91r29922                  | 99i77710                  | 0.0000\tFalse\n",
            "56c77468                  | 57c77718                  | 0.0002\tFalse\n",
            "94p94428                  | 19p99918                  | 0.0000\tFalse\n",
            "667j2114                  | 66j22928                  | 0.0000\tFalse\n",
            "17w91622                  | 77w99722                  | 0.0000\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "[1000/4500] Train loss: 0.47424, Valid loss: 0.18630, Elapsed_time: 873.21635\n",
            "Current_accuracy : 86.603, Current_norm_ED  : 0.96\n",
            "Best_accuracy    : 86.603, Best_norm_ED     : 0.96\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "45r42741                  | 45r42741                  | 0.8724\tTrue\n",
            "35q88216                  | 35q88216                  | 0.8653\tTrue\n",
            "12m99116                  | 12m99116                  | 0.6713\tTrue\n",
            "65b16372                  | 65b16372                  | 0.9246\tTrue\n",
            "46q49569                  | 46q49569                  | 0.9255\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[1500/4500] Train loss: 0.13192, Valid loss: 0.17555, Elapsed_time: 1301.17145\n",
            "Current_accuracy : 87.617, Current_norm_ED  : 0.96\n",
            "Best_accuracy    : 87.617, Best_norm_ED     : 0.96\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "27v66436                  | 22v66436                  | 0.3230\tFalse\n",
            "15w43529                  | 15w43529                  | 0.9404\tTrue\n",
            "75u83445                  | 75u83445                  | 0.7522\tTrue\n",
            "82u87755                  | 82u84755                  | 0.8727\tFalse\n",
            "91k11515                  | 91k11515                  | 0.9710\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[2000/4500] Train loss: 0.09811, Valid loss: 0.18221, Elapsed_time: 1731.14459\n",
            "Current_accuracy : 87.900, Current_norm_ED  : 0.96\n",
            "Best_accuracy    : 87.900, Best_norm_ED     : 0.96\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "57p59263                  | 57p59263                  | 0.9872\tTrue\n",
            "45b23399                  | 45b23399                  | 0.9859\tTrue\n",
            "11b65516                  | 11b65516                  | 0.9644\tTrue\n",
            "26m19216                  | 26m19216                  | 0.9389\tTrue\n",
            "80u86429                  | 80u86429                  | 0.9837\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[2500/4500] Train loss: 0.07517, Valid loss: 0.20142, Elapsed_time: 2158.35492\n",
            "Current_accuracy : 85.083, Current_norm_ED  : 0.95\n",
            "Best_accuracy    : 87.900, Best_norm_ED     : 0.96\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "75m67971                  | 75m67971                  | 0.9845\tTrue\n",
            "61c21274                  | 61c21274                  | 0.9761\tTrue\n",
            "32m41699                  | 42m41699                  | 0.8859\tFalse\n",
            "17q15312                  | 17q15312                  | 0.9378\tTrue\n",
            "85i40322                  | 85i40322                  | 0.9717\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[3000/4500] Train loss: 0.05960, Valid loss: 0.19464, Elapsed_time: 2584.84894\n",
            "Current_accuracy : 87.191, Current_norm_ED  : 0.96\n",
            "Best_accuracy    : 87.900, Best_norm_ED     : 0.96\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "74b22655                  | 74b22655                  | 0.9627\tTrue\n",
            "79w62929                  | 79w62929                  | 0.9874\tTrue\n",
            "34q74755                  | 34q74755                  | 0.5764\tTrue\n",
            "82i54859                  | 82i54859                  | 0.9953\tTrue\n",
            "84b23167                  | 84b23167                  | 0.3253\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[3500/4500] Train loss: 0.04436, Valid loss: 0.20294, Elapsed_time: 3012.03073\n",
            "Current_accuracy : 86.968, Current_norm_ED  : 0.96\n",
            "Best_accuracy    : 87.900, Best_norm_ED     : 0.96\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "11c66855                  | 11u66855                  | 0.6272\tFalse\n",
            "12i42874                  | 12i42874                  | 0.9935\tTrue\n",
            "55832j53                  | 35j23855                  | 0.6850\tFalse\n",
            "81w71632                  | 81w71632                  | 0.9964\tTrue\n",
            "47y41961                  | 47y41961                  | 0.9925\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[4000/4500] Train loss: 0.03626, Valid loss: 0.22799, Elapsed_time: 3438.61566\n",
            "Current_accuracy : 87.171, Current_norm_ED  : 0.96\n",
            "Best_accuracy    : 87.900, Best_norm_ED     : 0.96\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "11z90211                  | 11z90211                  | 0.9962\tTrue\n",
            "84r48318                  | 84r48318                  | 0.7043\tTrue\n",
            "67z23473                  | 67z23473                  | 0.9975\tTrue\n",
            "q                         | qq19                      | 0.0635\tFalse\n",
            "95t77799                  | 95t77799                  | 0.9946\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[4500/4500] Train loss: 0.03101, Valid loss: 0.21949, Elapsed_time: 3864.77691\n",
            "Current_accuracy : 87.981, Current_norm_ED  : 0.96\n",
            "Best_accuracy    : 87.981, Best_norm_ED     : 0.96\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "77m81555                  | 77m81555                  | 0.9832\tTrue\n",
            "82c16538                  | 82c16538                  | 0.9983\tTrue\n",
            "44c14233                  | 4u112                     | 0.1634\tFalse\n",
            "57c27122                  | 57c27122                  | 0.9982\tTrue\n",
            "43n82688                  | 43n82688                  | 0.9702\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "end the training\n"
          ]
        }
      ],
      "source": [
        "!python3 train.py \\\n",
        "--train_data /content/deep-text-recognition-benchmark/DTRB_LMDB/train --valid_data /content/deep-text-recognition-benchmark/DTRB_LMDB/validation \\\n",
        "--select_data / --batch_ratio 1 --batch_max_length 8 --valInterval 500 --num_iter 4500\\\n",
        "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ICUsV5kzvDl",
        "outputId": "f37d5a05-d6f1-416a-e219-9e7143dcea21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n",
            "loading pretrained model from saved_models/TPS-ResNet-BiLSTM-Attn-Seed1111/best_accuracy.pth\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "--------------------------------------------------------------------------------\n",
            "image_path               \tpredicted_labels         \tconfidence score\n",
            "--------------------------------------------------------------------------------\n",
            "my_test/1.jpg            \t71q91712                 \t0.9774\n",
            "my_test/2.jpg            \t56q86626                 \t0.9943\n",
            "my_test/3.jpg            \t65q35242                 \t0.9969\n",
            "my_test/4.jpg            \t63m45812                 \t0.9399\n",
            "my_test/5.jpg            \t18r68484                 \t0.9230\n",
            "my_test/6.jpg            \t81r93136                 \t0.9880\n",
            "my_test/7.jpg            \t13c78212                 \t0.9280\n",
            "my_test/8.jpg            \t92r16142                 \t0.9963\n",
            "my_test/9.jpg            \t13728212                 \t0.4436\n",
            "my_test/10.jpg           \t85r76288                 \t0.9661\n",
            "my_test/11.jpg           \t48c35812                 \t0.9906\n",
            "my_test/12.jpg           \t43e15412                 \t0.6507\n",
            "my_test/13.jpg           \t83n48412                 \t0.9937\n",
            "my_test/14.jpg           \t16n24112                 \t0.6840\n",
            "my_test/15.jpg           \t23v29642                 \t0.8698\n",
            "my_test/16.jpg           \t16b56412                 \t0.9791\n",
            "my_test/17.jpg           \t62j31512                 \t0.9744\n",
            "my_test/18.jpg           \t65v24774                 \t0.9824\n",
            "my_test/19.jpg           \t78c77936                 \t0.9884\n",
            "my_test/20.jpg           \t14v88245                 \t0.5708\n"
          ]
        }
      ],
      "source": [
        "! python3 demo.py \\\n",
        "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn \\\n",
        "--image_folder my_test/ \\\n",
        "--saved_model saved_models/TPS-ResNet-BiLSTM-Attn-Seed1111/best_accuracy.pth"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
