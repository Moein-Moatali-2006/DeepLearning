{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5pyDoiXwmNM",
        "outputId": "1725b2a7-5751-4433-966b-31c519828191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'deep-text-recognition-benchmark'...\n",
            "remote: Enumerating objects: 499, done.\u001b[K\n",
            "remote: Counting objects: 100% (225/225), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 499 (delta 208), reused 200 (delta 200), pack-reused 274 (from 1)\u001b[K\n",
            "Receiving objects: 100% (499/499), 3.05 MiB | 21.72 MiB/s, done.\n",
            "Resolving deltas: 100% (308/308), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/clovaai/deep-text-recognition-benchmark.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbfvSLzew3vv",
        "outputId": "a1bbae8e-7944-442e-fd31-4dbb6b06ec4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/deep-text-recognition-benchmark\n"
          ]
        }
      ],
      "source": [
        "%cd deep-text-recognition-benchmark/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6p3q1YEv8EX",
        "outputId": "7828248a-7ca6-40f6-d44b-3bbd989b65fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/297.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/297.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q fire\n",
        "!pip install -q lmdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCO7iZ20xs3O"
      },
      "outputs": [],
      "source": [
        "import lmdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXll8oASy06Q",
        "outputId": "4c56dce1-dd10-4f1d-ba89-51ec0cc6f5b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1b59rXuGGmKne1AuHnkgDzoYgKeETNMv9\n",
            "From (redirected): https://drive.google.com/uc?id=1b59rXuGGmKne1AuHnkgDzoYgKeETNMv9&confirm=t&uuid=8e65627a-68ef-4cb5-8358-43d9e6bb999c\n",
            "To: /content/deep-text-recognition-benchmark/TPS-ResNet-BiLSTM-Attn.pth\n",
            "100% 199M/199M [00:02<00:00, 68.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1b59rXuGGmKne1AuHnkgDzoYgKeETNMv9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE1DojrnxAXs",
        "outputId": "385a9f9d-4eeb-4137-e962-02bfc26510c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n",
            "loading pretrained model from TPS-ResNet-BiLSTM-Attn.pth\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "--------------------------------------------------------------------------------\n",
            "image_path               \tpredicted_labels         \tconfidence score\n",
            "--------------------------------------------------------------------------------\n",
            "my_test/Text_fa.png      \treconsing                \t0.0000\n",
            "my_test/persian_plate.png\ttagysher                 \t0.0002\n",
            "my_test/plate.png        \t284fh3                   \t0.5594\n",
            "my_test/text_en.png      \tmureuromer               \t0.0588\n"
          ]
        }
      ],
      "source": [
        "!python3 demo.py \\\n",
        "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn \\\n",
        "--image_folder my_test/ \\\n",
        "--saved_model TPS-ResNet-BiLSTM-Attn.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i9zm5yaz0S9",
        "outputId": "2e78ecc4-45ba-4954-c428-60fe3627b32a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ubkg7E2vGEOqS4K_quwf9Vl-i8IVpklM\n",
            "From (redirected): https://drive.google.com/uc?id=1ubkg7E2vGEOqS4K_quwf9Vl-i8IVpklM&confirm=t&uuid=eda6be75-3ad3-41e5-b35f-1c36a6d528f4\n",
            "To: /content/deep-text-recognition-benchmark/plate_img-train.zip\n",
            "100% 196M/196M [00:03<00:00, 61.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1ubkg7E2vGEOqS4K_quwf9Vl-i8IVpklM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7ifvJG40C-B",
        "outputId": "8597eba6-a34f-448e-a950-703a8225fe1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1AL5Zsg2hDqcwF8ZmR0MJTbjgXIoE5W-I\n",
            "From (redirected): https://drive.google.com/uc?id=1AL5Zsg2hDqcwF8ZmR0MJTbjgXIoE5W-I&confirm=t&uuid=5cf69cfb-026c-46c7-b3cf-5114cf2b404d\n",
            "To: /content/deep-text-recognition-benchmark/plate_img-validation.zip\n",
            "100% 27.2M/27.2M [00:00<00:00, 108MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1AL5Zsg2hDqcwF8ZmR0MJTbjgXIoE5W-I"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSQPgsxQ9Am1",
        "outputId": "4815a2d4-fe8b-46c8-d771-909ab38fec13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train/\n",
            "train/00001.jpg\n",
            "train/00001.xml\n",
            "train/00002.jpg\n",
            "train/00002.xml\n",
            "train/00004.jpg\n",
            "train/00004.xml\n",
            "train/00006.jpg\n",
            "train/00006.xml\n",
            "train/00008.jpg\n",
            "train/00008.xml\n",
            "train/00011.jpg\n",
            "train/00011.xml\n",
            "train/00014.jpg\n",
            "train/00014.xml\n",
            "train/00015.jpg\n",
            "train/00015.xml\n",
            "train/00016.jpg\n",
            "train/00016.xml\n",
            "train/00017.jpg\n",
            "train/00017.xml\n",
            "train/00021.jpg\n",
            "train/00021.xml\n",
            "train/00022.jpg\n",
            "train/00022.xml\n",
            "train/00023.jpg\n",
            "train/00023.xml\n",
            "train/00024.jpg\n",
            "train/00024.xml\n",
            "train/00025.jpg\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "zip_path = \"/content/deep-text-recognition-benchmark/plate_img-train.zip\"\n",
        "\n",
        "with ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_content = zip_ref.namelist()\n",
        "\n",
        "for name in zip_content[:30]:  # فقط ۳۰ تا اولی برای نمونه\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1d40MhV6X0I"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from zipfile import ZipFile\n",
        "\n",
        "zip_path = \"/content/deep-text-recognition-benchmark/plate_img-train.zip\"\n",
        "extract_dir = \"/content/plate_data\"\n",
        "image_dir = os.path.join(extract_dir, \"train\")  # درست شد\n",
        "\n",
        "# 1. استخراج فایل zip\n",
        "with ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# 2. آماده‌سازی فایل خروجی\n",
        "output_file = os.path.join(extract_dir, \"labels.txt\")\n",
        "\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as out:\n",
        "    for fname in os.listdir(image_dir):\n",
        "        if fname.endswith(\".xml\"):\n",
        "            xml_path = os.path.join(image_dir, fname)\n",
        "            tree = ET.parse(xml_path)\n",
        "            root = tree.getroot()\n",
        "\n",
        "            chars = []\n",
        "            for obj in root.findall(\"object\"):\n",
        "                char = obj.find(\"name\").text\n",
        "                chars.append(char)\n",
        "\n",
        "            label = \"\".join(chars)\n",
        "            img_name = fname.replace(\".xml\", \".jpg\")\n",
        "            img_path = f\"train/{img_name}\"  # درست شد\n",
        "            out.write(f\"{img_path}\\t{label}\\n\")\n",
        "\n",
        "print(\"✅ labels.txt ساخته شد.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZFPUH_EG01CU",
        "outputId": "15ad9219-72b1-492e-b33a-1c7d86b1038b"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-19-737d8d2e4340>, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-737d8d2e4340>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python create_lmdb_dataset.py \\\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "!python create_lmdb_dataset.py \\\n",
        "  --inputPath path_to_images \\\n",
        "  --gtFile path_to_labels.txt \\\n",
        "  --outputPath path_to_lmdb_dataset"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}